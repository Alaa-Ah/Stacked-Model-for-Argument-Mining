{"id": 17728, "annotations": [{"id": 17831, "completed_by": 2, "result": [{"type": "labels", "value": {"end": 9, "text": "Operator", "start": 0, "labels": ["OPERATOR"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}, {"type": "labels", "value": {"end": 68, "text": ": Your next question comes from Colin Sebastian from Baird.", "start": 10, "labels": ["INTRO"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}, {"type": "labels", "value": {"end": 84, "text": "Colin Sebastian", "start": 68, "labels": ["ANALYST"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}, {"type": "labels", "value": {"end": 755, "text": ": Great. Maybe a quick follow-up on the platform safety issue, maybe specifically with respect to broadcast. Wondering how close you are in terms of the ability to prevent harmful posts or videos from reaching users on a real-time basis? And how much of this can realistically be done today using AI versus more manual processes? And then secondly, Mark, just considering the fast adoption of voice interactions in interfaces online, how should we think about Facebook's strategy and competitive positioning as an opportunity to strengthen the connections that exist between the apps or would voice interaction being a distinct feature perhaps within the apps? Thank you.", "start": 85, "labels": ["QUESTION"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}, {"type": "labels", "value": {"end": 771, "text": "Mark Zuckerberg", "start": 755, "labels": ["REPRESENTATIVE"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}, {"type": "labels", "value": {"end": 3814, "text": ": Sure. So on safety, I think given the volume of content that people share, if you want to have any hope of doing it in real time, the only hope is building AI systems that can either identify things and handle them proactively or at the very least, flag them for a lot of people who work for us who can then look at them rather than waiting for people in our community to flag those after they've already seen them. The reactive model of waiting for people in the community to flag them guarantees that by the time that we get to look at an issue someone has already seen that content, which is not the state that we want to be in. So the state that we're trying to get to and hold ourselves accountable to is where we have these transparency reports \u2013 right now every six months, but we want to get to quarterly on those soon. And in those transparency reports, we break down every category of harmful content, everything from terrorism, to hate speech, to bullying, to nudity. And in each one, we talk about the prevalence of the content that people see because we think what matters is the number of impressions or people who are seeing the content, not just \u2013 not if a lot of people are sharing something but no one sees it \u2013 but what is actually getting seen. One piece of content that gets seen by a lot of people is a big deal. And then in these reports, we also talk about and show what percent of the content we handle proactively and identify proactively. And our goal is to get that to be as high as possible. In areas like terrorism, for Al Qaeda and ISIS related content, now 99% of the content that we take down in the category our systems flag proactively before anyone sees it. That's what really good looks like. I don't know that in every category we're going to be able to get to 99%; certainly not in the next six months or a year. But my hope would be that we can get to 90-plus percent on most of these categories within the next couple of years. And that's I think the best hope for doing this. That's going to be a bit continued investment and something that we really care about getting right. The other question was about voice. Most of what we build \u2013 one of the things that\u2019s different about Facebook and social products is more of it is about people interacting with each other than just people interacting with us, right? And so we\u2019re certainly very focused on things like video calling and voice calling and ways that people can communicate with voice. We have worked on some voice products on Portal; that\u2019s an important way that people interact. And having Portal out in the market has been very valuable in terms of seeing how people want to use that and for \u2013 so our teams can have a real target to shoot at and iterate on and continue improving week over week. That\u2019s been a meaningful improvement. But in all of these different ways, voice and how people interact with each other and eventually building products that allow people to interface with our products through that, we\u2019re quite focused on this.", "start": 772, "labels": ["ANSWER"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}], "was_cancelled": false, "ground_truth": true, "created_at": "2022-02-04T10:25:34.011822Z", "updated_at": "2022-02-04T10:25:34.011827Z", "lead_time": null, "prediction": {}, "result_count": 0, "task": 17728, "parent_prediction": null, "parent_annotation": null}], "data": {"year": 2019, "company": "FB", "my_text": "\nOperator: Your next question comes from Colin Sebastian from Baird.\nColin Sebastian: Great. Maybe a quick follow-up on the platform safety issue, maybe specifically with respect to broadcast. Wondering how close you are in terms of the ability to prevent harmful posts or videos from reaching users on a real-time basis? And how much of this can realistically be done today using AI versus more manual processes? And then secondly, Mark, just considering the fast adoption of voice interactions in interfaces online, how should we think about Facebook's strategy and competitive positioning as an opportunity to strengthen the connections that exist between the apps or would voice interaction being a distinct feature perhaps within the apps? Thank you.\nMark Zuckerberg: Sure. So on safety, I think given the volume of content that people share, if you want to have any hope of doing it in real time, the only hope is building AI systems that can either identify things and handle them proactively or at the very least, flag them for a lot of people who work for us who can then look at them rather than waiting for people in our community to flag those after they've already seen them. The reactive model of waiting for people in the community to flag them guarantees that by the time that we get to look at an issue someone has already seen that content, which is not the state that we want to be in. So the state that we're trying to get to and hold ourselves accountable to is where we have these transparency reports \u2013 right now every six months, but we want to get to quarterly on those soon. And in those transparency reports, we break down every category of harmful content, everything from terrorism, to hate speech, to bullying, to nudity. And in each one, we talk about the prevalence of the content that people see because we think what matters is the number of impressions or people who are seeing the content, not just \u2013 not if a lot of people are sharing something but no one sees it \u2013 but what is actually getting seen. One piece of content that gets seen by a lot of people is a big deal. And then in these reports, we also talk about and show what percent of the content we handle proactively and identify proactively. And our goal is to get that to be as high as possible. In areas like terrorism, for Al Qaeda and ISIS related content, now 99% of the content that we take down in the category our systems flag proactively before anyone sees it. That's what really good looks like. I don't know that in every category we're going to be able to get to 99%; certainly not in the next six months or a year. But my hope would be that we can get to 90-plus percent on most of these categories within the next couple of years. And that's I think the best hope for doing this. That's going to be a bit continued investment and something that we really care about getting right. The other question was about voice. Most of what we build \u2013 one of the things that\u2019s different about Facebook and social products is more of it is about people interacting with each other than just people interacting with us, right? And so we\u2019re certainly very focused on things like video calling and voice calling and ways that people can communicate with voice. We have worked on some voice products on Portal; that\u2019s an important way that people interact. And having Portal out in the market has been very valuable in terms of seeing how people want to use that and for \u2013 so our teams can have a real target to shoot at and iterate on and continue improving week over week. That\u2019s been a meaningful improvement. But in all of these different ways, voice and how people interact with each other and eventually building products that allow people to interface with our products through that, we\u2019re quite focused on this.", "quarter": 1}}
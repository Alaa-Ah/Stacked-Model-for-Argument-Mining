{"id": 17614, "annotations": [{"id": 17717, "completed_by": 2, "result": [{"type": "labels", "value": {"end": 9, "text": "Operator", "start": 0, "labels": ["OPERATOR"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}, {"type": "labels", "value": {"end": 80, "text": ": Your next question comes from the line of John Blackledge from Cowen.", "start": 10, "labels": ["INTRO"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}, {"type": "labels", "value": {"end": 96, "text": "John Blackledge", "start": 80, "labels": ["ANALYST"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}, {"type": "labels", "value": {"end": 560, "text": ": Thanks, two questions. Mark, you mentioned adding 3,000 reviewers to content at Facebook. Could artificial intelligence be used over time to help solve some of the monitoring? And then just more broadly, how is AI being employed in the processes at the company now versus a couple years ago? And then second item would be, could newer ad units like mid-roll video help mitigate the decel from the lower ad load growth contribution in second half 2017? Thank you.", "start": 97, "labels": ["QUESTION"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}, {"type": "labels", "value": {"end": 583, "text": "Mark Elliot Zuckerberg", "start": 560, "labels": ["REPRESENTATIVE"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}, {"type": "labels", "value": {"end": 2391, "text": ": I'll talk to the content and AI questions, and then someone else can talk about the ad piece. The short answer is yes. AI tools over time will be able to do a better job of flagging things for the set of people who are in the Community Ops teams that we can prioritize what we look at. A lot of what we're trying to do here is not just about getting content off Facebook. Last week there was this case where someone was using Facebook Live to broadcast \u2013 or was thinking about suicide. And we saw that video and actually didn't take it down and helped get in touch with law enforcement who used that live video to communicate with that person and help save their life. So a lot of what we're trying to do is not just about taking the content down, but also about helping people when they're in need on the platform, and we take that very, very seriously. Over time, the AI tools will get better. Right now there are certain things that AI can do in terms of understanding text and understanding what's in a photo and what's in a video. That will get better over time. That will take a period of years, though, to really reach the quality level that we want. So for a while, our strategy has been to just continue building as good tools as we can because no matter how many people we have on the team, we're never going to be able to look at everything. So that's going be a big challenge. But given the importance of this and how quickly live video is growing, we wanted to make sure that we doubled down on this and made sure we provided as safe of an experience for the community as we can, which is why we're almost doubling the size of the Community Ops team to focus on some of these issues around safety on live video. But over time for sure, more AI will do this, but this is over a period of years.", "start": 584, "labels": ["ANSWER"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}, {"type": "labels", "value": {"end": 2407, "text": "David M. Wehner", "start": 2391, "labels": ["REPRESENTATIVE"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}, {"type": "labels", "value": {"end": 3080, "text": ": John, I think your question then was on Ad Breaks and then the mid-roll type of format. I think there we're testing the ability and are putting short Ad Breaks into longer-form live and on-demand videos. Tests are going well, but it's really early days to talk about that being a significant contributor, so we're working to continue to make those products better and continuing those tests, but it's early. On that front, we're focused on building out the best video experiences for our community and growing longer-form content as a priority. And Ad Breaks is going to allow us to have a monetization strategy with that longer-form content. But like I said, it's early.", "start": 2408, "labels": ["ANSWER"]}, "origin": "manual", "to_name": "text", "from_name": "label-intro"}], "was_cancelled": false, "ground_truth": true, "created_at": "2022-02-04T10:25:34.002906Z", "updated_at": "2022-02-04T10:25:34.002911Z", "lead_time": null, "prediction": {}, "result_count": 0, "task": 17614, "parent_prediction": null, "parent_annotation": null}], "data": {"year": 2017, "company": "FB", "my_text": "\nOperator: Your next question comes from the line of John Blackledge from Cowen.\nJohn Blackledge: Thanks, two questions. Mark, you mentioned adding 3,000 reviewers to content at Facebook. Could artificial intelligence be used over time to help solve some of the monitoring? And then just more broadly, how is AI being employed in the processes at the company now versus a couple years ago? And then second item would be, could newer ad units like mid-roll video help mitigate the decel from the lower ad load growth contribution in second half 2017? Thank you.\nMark Elliot Zuckerberg: I'll talk to the content and AI questions, and then someone else can talk about the ad piece. The short answer is yes. AI tools over time will be able to do a better job of flagging things for the set of people who are in the Community Ops teams that we can prioritize what we look at. A lot of what we're trying to do here is not just about getting content off Facebook. Last week there was this case where someone was using Facebook Live to broadcast \u2013 or was thinking about suicide. And we saw that video and actually didn't take it down and helped get in touch with law enforcement who used that live video to communicate with that person and help save their life. So a lot of what we're trying to do is not just about taking the content down, but also about helping people when they're in need on the platform, and we take that very, very seriously. Over time, the AI tools will get better. Right now there are certain things that AI can do in terms of understanding text and understanding what's in a photo and what's in a video. That will get better over time. That will take a period of years, though, to really reach the quality level that we want. So for a while, our strategy has been to just continue building as good tools as we can because no matter how many people we have on the team, we're never going to be able to look at everything. So that's going be a big challenge. But given the importance of this and how quickly live video is growing, we wanted to make sure that we doubled down on this and made sure we provided as safe of an experience for the community as we can, which is why we're almost doubling the size of the Community Ops team to focus on some of these issues around safety on live video. But over time for sure, more AI will do this, but this is over a period of years.\nDavid M. Wehner: John, I think your question then was on Ad Breaks and then the mid-roll type of format. I think there we're testing the ability and are putting short Ad Breaks into longer-form live and on-demand videos. Tests are going well, but it's really early days to talk about that being a significant contributor, so we're working to continue to make those products better and continuing those tests, but it's early. On that front, we're focused on building out the best video experiences for our community and growing longer-form content as a priority. And Ad Breaks is going to allow us to have a monetization strategy with that longer-form content. But like I said, it's early.", "quarter": 1}}